{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART TWO \n",
    "\n",
    "## Content List- Part 2\n",
    "\n",
    "- [Data Cleaning and EDA](#Data-Cleaning-and-EDA)\n",
    "- [Preprocessing and Modeling](#Preprocessing-and-Modeling)\n",
    "- [Evaluation and Conceptual Understanding](#Evaluation-and-Conceptual-Understanding)\n",
    "- [Conclusion and Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:48.803327Z",
     "start_time": "2019-07-07T20:19:47.709238Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import text, _stop_words\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Dataframe from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:48.825869Z",
     "start_time": "2019-07-07T20:19:48.806812Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('./data/master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:48.846472Z",
     "start_time": "2019-07-07T20:19:48.828495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:48.865819Z",
     "start_time": "2019-07-07T20:19:48.852008Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Post Text          0\n",
       "Subreddit          0\n",
       "Length of Title    0\n",
       "ID                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nulls\n",
    "master_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:48.951354Z",
     "start_time": "2019-07-07T20:19:48.941285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1525, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of new, combined dataframe\n",
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:49.111764Z",
     "start_time": "2019-07-07T20:19:49.100603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Post Text', 'Subreddit', 'Length of Title', 'ID'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:49.294460Z",
     "start_time": "2019-07-07T20:19:49.285083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.02754098360656"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['Length of Title'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:49.506963Z",
     "start_time": "2019-07-07T20:19:49.498141Z"
    }
   },
   "outputs": [],
   "source": [
    "#set feature and targets\n",
    "X = master_df[['Post Text', 'Length of Title']]\n",
    "y = master_df['Subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:49.716032Z",
     "start_time": "2019-07-07T20:19:49.704545Z"
    }
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Baseline Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Accuracy is our metric, it is vital to determine a baseline so that we can compare our results. We will do this by performing a quick analysis on the distribution of the classes, in order to see if there is any inherent imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:50.520387Z",
     "start_time": "2019-07-07T20:19:50.325211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.620419\n",
       "1    0.379581\n",
       "Name: Subreddit, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Accuracy\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline Accuracy of 55.58% is important for the model as it provides a metric on which the model should be judged. 55% is the equivalent of random chance pick by the Majority class, even higher than a coin flip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:50.745332Z",
     "start_time": "2019-07-07T20:19:50.735006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1143, 2)\n",
      "(1143,)\n",
      "(382, 2)\n",
      "(382,)\n"
     ]
    }
   ],
   "source": [
    "#show us the shape of our data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amending stop word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:51.172429Z",
     "start_time": "2019-07-07T20:19:51.161074Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "15\n",
      "341\n",
      "332\n"
     ]
    }
   ],
   "source": [
    "additional_politics_english_stop = ['www', 'things', 'does', 'x200b', 'amp', 'want', 'watch',\n",
    "                           'just', 'like', 'https', 'com', 'republican', 'republicans',\n",
    "                           'libertarians', 'democrats', 'democrat', 'people', 'libertarian',\n",
    "                           'says', 'say', 'did', 'this', 'conservative', 'conservatives' ]\n",
    "\n",
    "additional_english_stop = ['www', 'things', 'does', 'x200b', 'amp',\n",
    "                           'just', 'like', 'https', 'com', 'watch', 'want',\n",
    "                           'says', 'say', 'did', 'this']\n",
    "\n",
    "new_stop_list = _stop_words.ENGLISH_STOP_WORDS.union(additional_english_stop)\n",
    "new_politics_english_stop_list = _stop_words.ENGLISH_STOP_WORDS.union(additional_politics_english_stop)\n",
    "print(len(_stop_words.ENGLISH_STOP_WORDS))\n",
    "print(len(additional_english_stop))\n",
    "print(len(new_politics_english_stop_list))\n",
    "print(len(new_stop_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:19:51.386134Z",
     "start_time": "2019-07-07T20:19:51.374034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'amp',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'com',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'did',\n",
       "           'do',\n",
       "           'does',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'https',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'just',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'like',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'say',\n",
       "           'says',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'things',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'want',\n",
       "           'was',\n",
       "           'watch',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'www',\n",
       "           'x200b',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline & GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing gridsearch with vectorizer, add onto X_train the feature desired (length of post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer with Logistic Regression\n",
    "\n",
    "CountVectorizer is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:34.230827Z",
     "start_time": "2019-07-07T20:19:52.372688Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.3, 0.4],\n",
       "                         'cvec__max_features': [None, 500, 1000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english',\n",
       "                                              frozenset({'a', 'about', 'above',\n",
       "                                                         'across', 'after',\n",
       "                                                         'afterwards', 'again',\n",
       "                                                         'against', 'all',\n",
       "                                                         'almost', 'alone',\n",
       "                                                         'along', 'already',\n",
       "                                                         'also', 'although',\n",
       "                                                         'always', 'am',\n",
       "                                                         'among', 'amongst',\n",
       "                                                         'amoungst', 'amount',\n",
       "                                                         'amp', 'an', 'and',\n",
       "                                                         'another', 'any',\n",
       "                                                         'anyhow', 'anyone',\n",
       "                                                         'anything', 'anyway', ...})],\n",
       "                         'lr__penalty': ['l2']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params_cvec_lr = {\n",
    "    'cvec__max_features': [None,500,1000],\n",
    "    'cvec__min_df': [2,3],\n",
    "    'cvec__max_df': [.3,.4,],\n",
    "    'cvec__ngram_range': [(1,2),(1,3)],\n",
    "    'cvec__stop_words': [None,'english',new_stop_list],\n",
    "    'lr__penalty': ['l2']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_cvec_lr, param_grid=pipe_params_cvec_lr, cv=5,n_jobs = -1,verbose = 1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:34.336957Z",
     "start_time": "2019-07-07T20:20:34.234990Z"
    }
   },
   "outputs": [],
   "source": [
    "cvlr_bestscore = gs.best_score_\n",
    "cvlr_params = gs.best_params_\n",
    "cvlr_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "cvlr_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "cvlr = ('CountVec with LogReg', cvlr_bestscore, cvlr_params, cvlr_train, cvlr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:34.435864Z",
     "start_time": "2019-07-07T20:20:34.339522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score: 0.7576649046196277\n",
      "Best Parameters: {'cvec__max_df': 0.3, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': frozenset({'wherever', 'no', 'did', 'upon', 'nobody', 'empty', 'their', 'which', 'formerly', 'how', 'whereby', 'whereas', 'system', 'am', 'they', 'another', 'i', 'ten', 'x200b', 'though', 'less', 'part', 'do', 'thru', 'latter', 'have', 'eg', 'nothing', 'whether', 'too', 'before', 'cry', 'along', 'mostly', 'any', 'ever', 'here', 'sometime', 'fire', 'some', 'toward', 'all', 'both', 'then', 'whence', 'also', 'https', 'somehow', 'even', 'he', 'always', 'latterly', 'via', 'towards', 'several', 'made', 'etc', 'through', 'next', 'them', 'thus', 'who', 'amp', 'done', 'or', 'what', 'at', 'now', 'was', 'name', 'interest', 'besides', 'anything', 'has', 'more', 'becomes', 'only', 'com', 'hereafter', 'whoever', 'thick', 'not', 'move', 'your', 'where', 'want', 'between', 'forty', 'on', 'give', 'such', 'say', 'hence', 'eight', 'across', 'ourselves', 'in', 'four', 'during', 'whole', 'de', 'neither', 'by', 'everyone', 'rather', 'once', 'although', 'against', 'seems', 'a', 'since', 'never', 'moreover', 'himself', 'within', 'out', 'other', 'when', 'it', 'anyway', 'bill', 'first', 'our', 'anywhere', 'beyond', 'whereupon', 'ltd', 'front', 'may', 'find', 'over', 'mine', 'show', 'every', 'many', 'like', 'among', 'ours', 'elsewhere', 'inc', 'had', 'under', 'alone', 're', 'until', 'yourselves', 'about', 'the', 'former', 'around', 'these', 'this', 'can', 'down', 'watch', 'cannot', 'further', 'into', 'so', 'things', 'while', 'his', 'together', 'ie', 'those', 'she', 'you', 'therein', 'below', 'already', 'thence', 'became', 'because', 'somewhere', 'indeed', 'per', 'except', 'none', 'yours', 'own', 'couldnt', 'amount', 'anyhow', 'whereafter', 'five', 'must', 'nowhere', 'something', 'everything', 'mill', 'beside', 'cant', 'same', 'whither', 'him', 'after', 'seem', 'twenty', 'still', 'of', 'con', 'therefore', 'please', 'me', 'nine', 'beforehand', 'nor', 'just', 'otherwise', 'perhaps', 'could', 'amongst', 'last', 'again', 'co', 'often', 'others', 'third', 'go', 'eleven', 'two', 'due', 'without', 'hereby', 'thereupon', 'thereby', 'describe', 'for', 'namely', 'onto', 'nevertheless', 'put', 'get', 'top', 'behind', 'off', 'yourself', 'to', 'fill', 'serious', 'from', 'hers', 'most', 'enough', 'take', 'back', 'fifteen', 'hereupon', 'hundred', 'detail', 'seemed', 'why', 'afterwards', 'whose', 'everywhere', 'sixty', 'been', 'amoungst', 'as', 'might', 'will', 'un', 'least', 'however', 'sincere', 'wherein', 'myself', 'its', 'themselves', 'if', 'thereafter', 'her', 'us', 'and', 'throughout', 'much', 'above', 'whatever', 'there', 'one', 'fifty', 'seeming', 'very', 'www', 'an', 'yet', 'whom', 'bottom', 'well', 'sometimes', 'meanwhile', 'either', 'hasnt', 'up', 'being', 'thin', 'that', 'herself', 'herein', 'itself', 'see', 'says', 'be', 'found', 'full', 'noone', 'twelve', 'whenever', 'three', 'are', 'is', 'side', 'call', 'my', 'anyone', 'six', 'become', 'than', 'someone', 'few', 'were', 'almost', 'with', 'keep', 'should', 'does', 'each', 'but', 'would', 'becoming', 'we', 'else'}), 'lr__penalty': 'l2'}\n",
      "Train Accuracy Score: 0.9615048118985127\n",
      "Test Accuracy Score: 0.7225130890052356\n"
     ]
    }
   ],
   "source": [
    "print(f'Best CV Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty strong results with CountVectorizer and Logistic Regression, with a Best CV Score: 0.79581; where the 'cvec__max_df': 0.3, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words':'english', 'lr__penalty': 'l2'.\n",
    "Train Accuracy Score: as above >0.9\n",
    "\n",
    "Test Accuracy Score: as above, >0.7\n",
    "\n",
    "The train score here was much better than the test score previously indicating that this model is overfit despite tuning the hyperparameters and the strong training data score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:59.219663Z",
     "start_time": "2019-07-07T20:20:34.441613Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n",
      "Best Score: 0.7314255919519078\n",
      "Best Parameters: {'lr__penalty': 'l2', 'tvec__max_df': 0.3, 'tvec__max_features': 1000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': None}\n",
      "Train Accuracy Score: 0.8547681539807525\n",
      "Test Accuracy Score: 0.7068062827225131\n"
     ]
    }
   ],
   "source": [
    "pipe_tvec_lr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params_tvec_lr = {\n",
    "    'tvec__max_features': [None,1000],\n",
    "    'tvec__min_df': [2,3,4],\n",
    "    'tvec__max_df': [.3,.5],\n",
    "    'tvec__ngram_range': [(1,1),(1,3)],\n",
    "    'tvec__stop_words': [None, new_stop_list,'english'],\n",
    "    'lr__penalty': ['l2']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_tvec_lr, param_grid=pipe_params_tvec_lr, cv=4, n_jobs=-1, verbose = 1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)\n",
    "\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:59.313257Z",
     "start_time": "2019-07-07T20:20:59.223948Z"
    }
   },
   "outputs": [],
   "source": [
    "tflr_bestscore = gs.best_score_\n",
    "tflr_params = gs.best_params_\n",
    "tflr_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "tflr_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "tflr = ('TF-IDF with LogReg',tflr_bestscore, tflr_params, tflr_train, tflr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:20:59.405542Z",
     "start_time": "2019-07-07T20:20:59.319133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7314255919519078\n",
      "Best Parameters: {'lr__penalty': 'l2', 'tvec__max_df': 0.3, 'tvec__max_features': 1000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': None}\n",
      "Train Accuracy Score: 0.8547681539807525\n",
      "Test Accuracy Score: 0.7068062827225131\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for TFIDF and Logistic Regression, with a Best cv score of ~0.7644; where the optimal parameters were 'tvec__max_df': 0.3, 'tvec__max_features': None, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': new_stop_list, 'lr__penalty': 'l2'.\n",
    "\n",
    "Train Accuracy Score: 0.9281974569932685\n",
    "\n",
    "Test Accuracy Score: 0.7982062780269058\n",
    "\n",
    "The train score was better than the test score indicating that this model is overfit despite tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer with Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:24:24.517979Z",
     "start_time": "2019-07-07T20:23:27.377255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 144 candidates, totalling 576 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'cvec__max_df': [0.4, 0.8],\n",
       "                         'cvec__max_features': [None, 500, 1000, 2500],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None,\n",
       "                                              frozenset({'a', 'about', 'above',\n",
       "                                                         'across', 'after',\n",
       "                                                         'afterwards', 'again',\n",
       "                                                         'against', 'all',\n",
       "                                                         'almost', 'alone',\n",
       "                                                         'along', 'already',\n",
       "                                                         'also', 'although',\n",
       "                                                         'always', 'am',\n",
       "                                                         'among', 'amongst',\n",
       "                                                         'amoungst', 'amount',\n",
       "                                                         'amp', 'an', 'and',\n",
       "                                                         'another', 'any',\n",
       "                                                         'anyhow', 'anyone',\n",
       "                                                         'anything', 'anyway', ...}),\n",
       "                                              'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_mnb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_cvec_mnb = {\n",
    "    'cvec__max_features': [None,500,1000,2500],\n",
    "    'cvec__min_df': [2,3],\n",
    "    'cvec__max_df': [.4, .8],\n",
    "    'cvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'cvec__stop_words': [None, new_stop_list,'english']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_cvec_mnb, param_grid=pipe_params_cvec_mnb, cv=4, n_jobs = 4, verbose = 1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:24:24.700425Z",
     "start_time": "2019-07-07T20:24:24.526997Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvmnb_bestscore = gs.best_score_\n",
    "cvmnb_params = gs.best_params_\n",
    "cvmnb_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "cvmnb_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "cvmnb = ('CountVec with MNB',cvmnb_bestscore, cvmnb_params, cvmnb_train, cvmnb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:22:31.580848Z",
     "start_time": "2019-07-07T20:22:31.480124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7427861612072139\n",
      "Best Parameters: {'cvec__max_df': 0.4, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n",
      "Train Accuracy Score: 0.8722659667541557\n",
      "Test Accuracy Score: 0.7303664921465969\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer and Multinomial Naive Bayes, with a Best cv score of 0.7255; where the optimal parameters were 'cvec__max_df': 0.4, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english'.\n",
    "\n",
    "Train Accuracy Score: 0.8833208676140614\n",
    "\n",
    "Test Accuracy Score: 0.7556053811659192\n",
    "\n",
    "The train score of approx 0.8833 was much better than the test score of 0.7556 indicating that this model is very overfit despite tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:29:21.776875Z",
     "start_time": "2019-07-07T20:27:55.488734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 216 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tvec__max_df': [0.2, 0.3, 0.4],\n",
       "                         'tvec__max_features': [None, 500, 1000, 3000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': [None,\n",
       "                                              frozenset({'a', 'about', 'above',\n",
       "                                                         'across', 'after',\n",
       "                                                         'afterwards', 'again',\n",
       "                                                         'against', 'all',\n",
       "                                                         'almost', 'alone',\n",
       "                                                         'along', 'already',\n",
       "                                                         'also', 'although',\n",
       "                                                         'always', 'am',\n",
       "                                                         'among', 'amongst',\n",
       "                                                         'amoungst', 'amount',\n",
       "                                                         'amp', 'an', 'and',\n",
       "                                                         'another', 'any',\n",
       "                                                         'anyhow', 'anyone',\n",
       "                                                         'anything', 'anyway', ...}),\n",
       "                                              'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tvec_mnb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_tvec_mnb = {\n",
    "    'tvec__max_features': [None,500,1000,3000],\n",
    "    'tvec__min_df': [2,3],\n",
    "    'tvec__max_df': [.2,.3,.4,],\n",
    "    'tvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'tvec__stop_words': [None, new_stop_list,'english']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_tvec_mnb, param_grid=pipe_params_tvec_mnb, cv=4, n_jobs = -1, verbose = 1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:29:21.910964Z",
     "start_time": "2019-07-07T20:29:21.784211Z"
    }
   },
   "outputs": [],
   "source": [
    "tfmnb_bestscore = gs.best_score_\n",
    "tfmnb_params = gs.best_params_\n",
    "tfmnb_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "tfmnb_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "\n",
    "tfmnb = ('TF-IDF with MNB',tfmnb_bestscore, tfmnb_params, tfmnb_train, tfmnb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:29:22.027031Z",
     "start_time": "2019-07-07T20:29:21.913179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7454054717212613\n",
      "Best Parameters: {'tvec__max_df': 0.3, 'tvec__max_features': 1000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': frozenset({'wherever', 'no', 'did', 'upon', 'nobody', 'empty', 'their', 'which', 'formerly', 'how', 'whereby', 'whereas', 'system', 'am', 'they', 'another', 'i', 'ten', 'x200b', 'though', 'less', 'part', 'do', 'thru', 'latter', 'have', 'eg', 'nothing', 'whether', 'too', 'before', 'cry', 'along', 'mostly', 'any', 'ever', 'here', 'sometime', 'fire', 'some', 'toward', 'all', 'both', 'then', 'whence', 'also', 'https', 'somehow', 'even', 'he', 'always', 'latterly', 'via', 'towards', 'several', 'made', 'etc', 'through', 'next', 'them', 'thus', 'who', 'amp', 'done', 'or', 'what', 'at', 'now', 'was', 'name', 'interest', 'besides', 'anything', 'has', 'more', 'becomes', 'only', 'com', 'hereafter', 'whoever', 'thick', 'not', 'move', 'your', 'where', 'want', 'between', 'forty', 'on', 'give', 'such', 'say', 'hence', 'eight', 'across', 'ourselves', 'in', 'four', 'during', 'whole', 'de', 'neither', 'by', 'everyone', 'rather', 'once', 'although', 'against', 'seems', 'a', 'since', 'never', 'moreover', 'himself', 'within', 'out', 'other', 'when', 'it', 'anyway', 'bill', 'first', 'our', 'anywhere', 'beyond', 'whereupon', 'ltd', 'front', 'may', 'find', 'over', 'mine', 'show', 'every', 'many', 'like', 'among', 'ours', 'elsewhere', 'inc', 'had', 'under', 'alone', 're', 'until', 'yourselves', 'about', 'the', 'former', 'around', 'these', 'this', 'can', 'down', 'watch', 'cannot', 'further', 'into', 'so', 'things', 'while', 'his', 'together', 'ie', 'those', 'she', 'you', 'therein', 'below', 'already', 'thence', 'became', 'because', 'somewhere', 'indeed', 'per', 'except', 'none', 'yours', 'own', 'couldnt', 'amount', 'anyhow', 'whereafter', 'five', 'must', 'nowhere', 'something', 'everything', 'mill', 'beside', 'cant', 'same', 'whither', 'him', 'after', 'seem', 'twenty', 'still', 'of', 'con', 'therefore', 'please', 'me', 'nine', 'beforehand', 'nor', 'just', 'otherwise', 'perhaps', 'could', 'amongst', 'last', 'again', 'co', 'often', 'others', 'third', 'go', 'eleven', 'two', 'due', 'without', 'hereby', 'thereupon', 'thereby', 'describe', 'for', 'namely', 'onto', 'nevertheless', 'put', 'get', 'top', 'behind', 'off', 'yourself', 'to', 'fill', 'serious', 'from', 'hers', 'most', 'enough', 'take', 'back', 'fifteen', 'hereupon', 'hundred', 'detail', 'seemed', 'why', 'afterwards', 'whose', 'everywhere', 'sixty', 'been', 'amoungst', 'as', 'might', 'will', 'un', 'least', 'however', 'sincere', 'wherein', 'myself', 'its', 'themselves', 'if', 'thereafter', 'her', 'us', 'and', 'throughout', 'much', 'above', 'whatever', 'there', 'one', 'fifty', 'seeming', 'very', 'www', 'an', 'yet', 'whom', 'bottom', 'well', 'sometimes', 'meanwhile', 'either', 'hasnt', 'up', 'being', 'thin', 'that', 'herself', 'herein', 'itself', 'see', 'says', 'be', 'found', 'full', 'noone', 'twelve', 'whenever', 'three', 'are', 'is', 'side', 'call', 'my', 'anyone', 'six', 'become', 'than', 'someone', 'few', 'were', 'almost', 'with', 'keep', 'should', 'does', 'each', 'but', 'would', 'becoming', 'we', 'else'})}\n",
      "Train Accuracy Score: 0.8678915135608049\n",
      "Test Accuracy Score: 0.7225130890052356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Results for TFIDF and Multinomial Naive Bayes, with a Best cv score of 0.7128; where the optimal parameters were 'tvec__max_df': 0.4, 'tvec__max_features': 1000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'.\n",
    "\n",
    "Train Accuracy Score: 0.9012715033657442\n",
    "\n",
    "Test Accuracy Score: 0.7623318385650224\n",
    "\n",
    "The train score of approx 0.9013 was much better than the test score of 0.7623 indicating that this model is very overfit despite tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:35:55.729143Z",
     "start_time": "2019-07-07T20:35:55.688627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('rfc', RandomForestClassifier())])\n",
    "\n",
    "rf_params = [{\n",
    "    'cvec__max_features': [None, 500,1000],\n",
    "    'cvec__min_df': [2,3],\n",
    "    'cvec__max_df': [.3,.4,.8],\n",
    "    'cvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'rfc__bootstrap': [True],\n",
    "    'rfc__max_features': [.5, .6],\n",
    "    'rfc__min_samples_leaf': [3,6],\n",
    "    'rfc__min_samples_split':[3,6],\n",
    "    'rfc__n_estimators':[10,100]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:52:58.980496Z",
     "start_time": "2019-07-07T20:35:56.202236Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 864 candidates, totalling 3456 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rfc', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'cvec__max_df': [0.3, 0.4, 0.8],\n",
       "                          'cvec__max_features': [None, 500, 1000],\n",
       "                          'cvec__min_df': [2, 3],\n",
       "                          'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                          'rfc__bootstrap': [True],\n",
       "                          'rfc__max_features': [0.5, 0.6],\n",
       "                          'rfc__min_samples_leaf': [3, 6],\n",
       "                          'rfc__min_samples_split': [3, 6],\n",
       "                          'rfc__n_estimators': [10, 100]}],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(rf_pipe, \n",
    "                   param_grid=rf_params, \n",
    "                   cv = 4,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:52:59.104187Z",
     "start_time": "2019-07-07T20:52:58.987322Z"
    }
   },
   "outputs": [],
   "source": [
    "cvrf_bestscore = gs.best_score_\n",
    "cvrf_params = gs.best_params_\n",
    "cvrf_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "cvrf_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "\n",
    "cvrf = ('CountVec with RandomForest',cvrf_bestscore, cvrf_params, cvrf_train, cvrf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:52:59.197869Z",
     "start_time": "2019-07-07T20:52:59.105901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7078149920255183\n",
      "Best Parameters: {'cvec__max_df': 0.4, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'rfc__bootstrap': True, 'rfc__max_features': 0.5, 'rfc__min_samples_leaf': 3, 'rfc__min_samples_split': 6, 'rfc__n_estimators': 10}\n",
      "Train Accuracy Score: 0.8538932633420823\n",
      "Test Accuracy Score: 0.6858638743455497\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model drastically improved on variance with the combination of CountVectorizer and RandomForestClassifier. The ideal param: were as follows: 'cvec__max_df': 0.9, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'rfc__bootstrap': True, 'rfc__max_features': 0.5, 'rfc__min_samples_leaf': 4, 'rfc__min_samples_split': 3, 'rfc__n_estimators': 100}\n",
    "\n",
    "Train Accuracy Score: 0.868362004487659\n",
    "\n",
    "Test Accuracy Score: 0.757847533632287\n",
    "\n",
    "Furthermore, the fact that the train accuracy score is still higher than the test accuracy score indicates the model is still overfit, albeit suffering from a lower bias as well as a lower variance than the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:06:14.870180Z",
     "start_time": "2019-07-07T21:06:14.862858Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "        ('tvec', TfidfVectorizer()),\n",
    "        ('rfc', RandomForestClassifier())])\n",
    "\n",
    "rf_params = [{\n",
    "    'tvec__max_features': [None],\n",
    "    'tvec__min_df': [2,4],\n",
    "    'tvec__max_df': [.3,.4, .5],\n",
    "    'tvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'tvec__stop_words': [None],\n",
    "    'rfc__bootstrap': [False, True],\n",
    "    'rfc__n_estimators': [10,100],\n",
    "    'rfc__max_features': [.5, .6, .7],\n",
    "    'rfc__min_samples_leaf': [10],\n",
    "    'rfc__min_samples_split':[3]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:11:53.335846Z",
     "start_time": "2019-07-07T21:06:15.061788Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 216 candidates, totalling 864 fits\n"
     ]
    }
   ],
   "source": [
    "gs= GridSearchCV(rf_pipe, \n",
    "                   param_grid=rf_params, \n",
    "                   cv = 4,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = 3)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:11:53.517466Z",
     "start_time": "2019-07-07T21:11:53.340363Z"
    }
   },
   "outputs": [],
   "source": [
    "tfrf_bestscore = gs.best_score_\n",
    "tfrf_params = gs.best_params_\n",
    "tfrf_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "tfrf_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "tfrf = ('TF-IDF with RandomForest', tfrf_bestscore, tfrf_params, tfrf_train, tfrf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:11:53.669911Z",
     "start_time": "2019-07-07T21:11:53.519311Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This models score with the combination of TFIDF and RandomForestClassifier average of .7457 was a little lower than the prior model.\n",
    "\n",
    "The ideal paramaters were as follows:{'rfc__bootstrap': False, 'rfc__max_features': 0.5, 'rfc__min_samples_leaf': 10, 'rfc__min_samples_split': 3, 'rfc__n_estimators': 100, 'tvec__max_df': 0.3, 'tvec__max_features': None, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': None.\n",
    "\n",
    "Train Accuracy Score: 0.8160059835452506\n",
    "\n",
    "Test Accuracy Score: 0.7309417040358744\n",
    "\n",
    "Furthermore, the fact that the train accuracy score is still higher than the test accuracy score indicates the model is still overfit (0.78608 vs 0.7511) , albeit suffering from a lower bias as well as a lower variance than the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:11:53.679789Z",
     "start_time": "2019-07-07T21:11:53.674093Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:16:29.475242Z",
     "start_time": "2019-07-07T21:11:53.689304Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'cvec__max_features': [None,500,1000],\n",
    "    'cvec__min_df': [3,5],\n",
    "    'cvec__max_df': [.4,.3],\n",
    "    'cvec__ngram_range': [(1,2),(2,3),(1,3)],\n",
    "    'cvec__stop_words': [None, 'english', new_stop_list],\n",
    "    'ada__learning_rate': [0.3,.5,.7]}\n",
    "\n",
    "gs= GridSearchCV(ada_pipe, \n",
    "                   param_grid=ada_params, \n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:16:29.636003Z",
     "start_time": "2019-07-07T21:16:29.480852Z"
    }
   },
   "outputs": [],
   "source": [
    "cvada_bestscore = gs.best_score_\n",
    "cvada_params = gs.best_params_\n",
    "cvada_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "cvada_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "cvada = ('CountVec with AdaBoost',cvada_bestscore, cvada_params, cvada_train, cvada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:16:29.796332Z",
     "start_time": "2019-07-07T21:16:29.638202Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:17:46.270925Z",
     "start_time": "2019-07-07T21:16:29.799176Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline([\n",
    "        ('tvec', TfidfVectorizer()),\n",
    "        ('ada', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "ada_params = {\n",
    "    'tvec__max_features': [None,500,1000],\n",
    "    'tvec__min_df': [2,3,4],\n",
    "    'tvec__max_df': [.5,.4,.3],\n",
    "    'tvec__ngram_range': [(1,1),(1,3)],\n",
    "    'tvec__stop_words': [None, 'english', new_stop_list],\n",
    "    'ada__learning_rate': [.5]}\n",
    "\n",
    "gs= GridSearchCV(ada_pipe, \n",
    "                   param_grid=ada_params, \n",
    "                   cv = 3,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:17:46.449003Z",
     "start_time": "2019-07-07T21:17:46.273474Z"
    }
   },
   "outputs": [],
   "source": [
    "tfada_bestscore = gs.best_score_\n",
    "tfada_params = gs.best_params_\n",
    "tfada_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "tfada_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "tfada = ('TF-IDF with AdaBoost',tfada_bestscore, tfada_params, tfada_train, tfada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:17:46.614450Z",
     "start_time": "2019-07-07T21:17:46.450717Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost with TFIDF proved the best so far, with lower variance and higher accuracy with optimal settings of:'ada__learning_rate': 0.5, 'tvec__max_df': 0.5, 'tvec__max_features': 500, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': new_stop_list.\n",
    "\n",
    "Train Accuracy Score: 0.8032909498878086\n",
    "\n",
    "Test Accuracy Score: 0.7645739910313901\n",
    "\n",
    "Scores show that there is still a tiny bit of overfit, but all in all this model should generalize the best to new data and so we will make our predictions using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:20:29.366323Z",
     "start_time": "2019-07-07T21:17:46.616874Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "xgb_params = {\n",
    "    'cvec__max_features': [None,500,1000],\n",
    "    'cvec__min_df': [3,5],\n",
    "    'cvec__max_df': [.4,.3],\n",
    "    'cvec__ngram_range': [(1,2),(2,3),(1,3)],\n",
    "    'cvec__stop_words': [None, 'english', new_stop_list]}\n",
    "\n",
    "gs= GridSearchCV(xgb_pipe, \n",
    "                   param_grid= xgb_params, \n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)\n",
    "\n",
    "cvxgb_bestscore = gs.best_score_\n",
    "cvxgb_params = gs.best_params_\n",
    "cvxgb_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "cvxgb_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "cvxgb = ('CountVec with XGBoost',cvxgb_bestscore, cvxgb_params, cvxgb_train, cvxgb_test)\n",
    "\n",
    "\n",
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:23:19.507597Z",
     "start_time": "2019-07-07T21:20:29.369673Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([\n",
    "        ('tvec', TfidfVectorizer()),\n",
    "        ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "xgb_params = {\n",
    "    'tvec__max_features': [None,500,1000],\n",
    "    'tvec__min_df': [2,3,4],\n",
    "    'tvec__max_df': [.5,.4,.3],\n",
    "    'tvec__ngram_range': [(1,1),(1,3)],\n",
    "    'tvec__stop_words': [None, 'english', new_stop_list]}\n",
    "\n",
    "gs= GridSearchCV(xgb_pipe, \n",
    "                   param_grid=xgb_params, \n",
    "                   cv = 3,\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train['Post Text'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:46:01.198114Z",
     "start_time": "2019-07-07T21:46:00.886059Z"
    }
   },
   "outputs": [],
   "source": [
    "tfxgb_bestscore = gs.best_score_\n",
    "tfxgb_params = gs.best_params_\n",
    "tfxgb_train = gs.score(X_train[\"Post Text\"],y_train)\n",
    "tfxgb_test= gs.score(X_test[\"Post Text\"],y_test)\n",
    "tfxgb = ('TF-IDF with XGBoost',tfxgb_bestscore, tfxgb_params, tfxgb_train, tfxgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:46:08.349469Z",
     "start_time": "2019-07-07T21:46:08.185487Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Best Score: {gs.best_score_}')\n",
    "print(f'Best Parameters: {gs.best_params_}')\n",
    "print(f'Train Accuracy Score: {gs.score(X_train[\"Post Text\"],y_train)}')\n",
    "print(f'Test Accuracy Score: {gs.score(X_test[\"Post Text\"],y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Utilizing the Top Performing Models\n",
    "#### I would classify two of the models as the best, the one with the highest overall score (lowest bias) and the one with the smallest overall difference between the train and test data (lowest variance). These models are tested out below with their optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:25.196468Z",
     "start_time": "2019-07-07T21:56:25.169964Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:25.378192Z",
     "start_time": "2019-07-07T21:56:25.361856Z"
    }
   },
   "outputs": [],
   "source": [
    "#define features\n",
    "X = master_df['Post Text']\n",
    "y = master_df['Subreddit']\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:25.674790Z",
     "start_time": "2019-07-07T21:56:25.667775Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate Adaboost with learning rate of 0.5 as optimized by GridSearch\n",
    "ada = AdaBoostClassifier(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:26.109203Z",
     "start_time": "2019-07-07T21:56:25.836365Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate TF-IDF and choose optimized hyperparameters from prior section's GridSearch\n",
    "tf= TfidfVectorizer(max_df= 0.4, \n",
    "                max_features= None,\n",
    "                min_df= 3,\n",
    "                ngram_range=(1, 3),\n",
    "                stop_words='english')\n",
    "\n",
    "\n",
    "# Fit our TfidfVectorizer on the training data and transform training data.\n",
    "X_train_tf = pd.DataFrame(tf.fit_transform(X_train).todense()\n",
    "                           ,columns = tf.get_feature_names())\n",
    "\n",
    "# Fit our TfidfVectorizer on the test data and transform training data.\n",
    "X_test_tf = pd.DataFrame(tf.transform(X_test).todense()\n",
    "                           ,columns = tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.755911Z",
     "start_time": "2019-07-07T21:56:26.112242Z"
    }
   },
   "outputs": [],
   "source": [
    "#fit the model to our data\n",
    "ada = ada.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.768343Z",
     "start_time": "2019-07-07T21:56:27.758863Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.786484Z",
     "start_time": "2019-07-07T21:56:27.772728Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.895401Z",
     "start_time": "2019-07-07T21:56:27.789640Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada.score(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.952395Z",
     "start_time": "2019-07-07T21:56:27.898774Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression and CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:27.961338Z",
     "start_time": "2019-07-07T21:56:27.955539Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate countvectorizer \n",
    "cvec = CountVectorizer(stop_words= new_stop_list,\n",
    "                       ngram_range=(1,2), min_df=2,\n",
    "                       max_features=None, max_df = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:28.124932Z",
     "start_time": "2019-07-07T21:56:27.967326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense()\n",
    "                           ,columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit our CountVectorizer on the test data and transform training data.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense()\n",
    "                           ,columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:28.209092Z",
     "start_time": "2019-07-07T21:56:28.129300Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate logisticregression\n",
    "lr = LogisticRegression()\n",
    "#fit data\n",
    "lr = lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:28.308647Z",
     "start_time": "2019-07-07T21:56:28.299966Z"
    }
   },
   "outputs": [],
   "source": [
    "#examine and verify shape\n",
    "X_test_cvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#examine and verify shape\n",
    "X_test_cvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:28.852315Z",
     "start_time": "2019-07-07T21:56:28.843882Z"
    }
   },
   "outputs": [],
   "source": [
    "#examine shape to verify a fit\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:29.061831Z",
     "start_time": "2019-07-07T21:56:29.036717Z"
    }
   },
   "outputs": [],
   "source": [
    "#score our logistic regression model on our fitted training data\n",
    "lr.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:29.256651Z",
     "start_time": "2019-07-07T21:56:29.231698Z"
    }
   },
   "outputs": [],
   "source": [
    "#score our logistic regression model on our fitted testing data\n",
    "lr.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Conceptual Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our models performed well, there are inherent limitations. For starters, we are asked to choose between a model that has very high variance (Logistic Regression) and one that has slightly worse accuracy but much lower variance (Adaboost). We are also limited by the computational requirements of putting every function into a gridsearch in order to tune the hyperparameters towards optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:46.267799Z",
     "start_time": "2019-07-07T21:56:46.261677Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # prepare configuration for cross validation test harness\n",
    "# seed = 42\n",
    "# # prepare models\n",
    "# models = []\n",
    "# models.append(('LR', LogisticRegression()))\n",
    "# models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('CART', DecisionTreeClassifier()))\n",
    "# models.append(('NB', GaussianNB()))\n",
    "# models.append(('SVM', SVC()))\n",
    "# # evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "# scoring = 'accuracy'\n",
    "# for name, model in models:\n",
    "# \tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# \tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "# \tresults.append(cv_results)\n",
    "# \tnames.append(name)\n",
    "# \tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "# \tprint(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:46.509115Z",
     "start_time": "2019-07-07T21:56:46.505793Z"
    }
   },
   "outputs": [],
   "source": [
    "# # boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:46.984041Z",
     "start_time": "2019-07-07T21:56:46.937184Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate predictions\n",
    "pred = ada.predict(X_test_tf)\n",
    "\n",
    "#generate confusion matrix\n",
    "conf = confusion_matrix( y_test,# True values.\n",
    "                     pred)# Predicted values.\n",
    "tn, fp, fn, tp = conf.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:47.499336Z",
     "start_time": "2019-07-07T21:56:47.493196Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert confusion matrix to dataframe\n",
    "df_ada= pd.DataFrame(conf, index =  ['actual republican', 'actual democrats'], columns = ['predicted republican', 'predicted democrats'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix- Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:48.563094Z",
     "start_time": "2019-07-07T21:56:48.551126Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides another visualization into the Accuracy score, in which there is approximately 1 in 5 misclassified data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:49.232658Z",
     "start_time": "2019-07-07T21:56:49.217366Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate predictions\n",
    "pred = lr.predict(X_test_cvec)\n",
    "\n",
    "#generate confusion matrix\n",
    "conf = confusion_matrix( y_test,# True values.\n",
    "                     pred)# Predicted values.\n",
    "tn, fp, fn, tp = conf.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:49.410074Z",
     "start_time": "2019-07-07T21:56:49.402127Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert confusion matrix to dataframe\n",
    "df_lr= pd.DataFrame(conf, index =  ['actual republican', 'actual democrats'], columns = ['predicted republican', 'predicted democrats'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T21:56:49.590196Z",
     "start_time": "2019-07-07T21:56:49.577508Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our models performed better than the baseline accuracy metric of ~55%, and although almost all of the models displayed different varying degrees of bias, variance and overfitting, the optimal models were LogisticRegression with CountVectorizer. These were determined not only in terms of overall raw accuracy, but in terms of variance and goodness of fit. \n",
    "\n",
    "In recommending this model to be used for the purpose of advertising companies who wish to target potential clients, it is important to weigh the pros and cons of 82.25% accuracy as offered by the Logistic Regression version of our model. This would mean that although 4 out of 5 recipients would be accurate, there would still exist a consistent 1 out of 5 audience that was not actually in the class described by our model. \n",
    "\n",
    "Additional features could also serve to improve the accuracy of our model, three ideas for that in future iterations include:\n",
    "\n",
    "1. Fixing typos or other spelling errors that may have impacted our model's ability to interpret text\n",
    "      \n",
    "2. Incorporating a sentiment analysis aspect, which would involve creating two bags of words in which  we define positive and negative sentiment words, then filter and weight them accordingly.\n",
    "      \n",
    "3. Incorporate a loudness aspect, in which we would look at the prevalence of capital letters in sequence. Although our preprocessing transforms all text to lowercase, there is an argument to be made for the inclusion of series of uppercase text as it usually conveys intense emotion. \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
